{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSpark : Illuminating Insights for Global Electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.1.1-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\welcome\\desktop\\data_spark_guvi\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\welcome\\desktop\\data_spark_guvi\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Downloading numpy-2.1.1-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 6.3/12.6 MB 32.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 30.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 29.2 MB/s eta 0:00:00\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.1.1 pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\3013831896.py:4: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  customers = pd.read_csv('CSV files\\Customers.csv', encoding='ISO-8859-1')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "customers = pd.read_csv('CSV files\\Customers.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerKey</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State Code</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Birthday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>Female</td>\n",
       "      <td>Lilly Harding</td>\n",
       "      <td>WANDEARAH EAST</td>\n",
       "      <td>SA</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>5523</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>7/3/1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325</td>\n",
       "      <td>Female</td>\n",
       "      <td>Madison Hull</td>\n",
       "      <td>MOUNT BUDD</td>\n",
       "      <td>WA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>6522</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>9/27/1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>554</td>\n",
       "      <td>Female</td>\n",
       "      <td>Claire Ferres</td>\n",
       "      <td>WINJALLOK</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>3380</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>5/26/1947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>786</td>\n",
       "      <td>Male</td>\n",
       "      <td>Jai Poltpalingada</td>\n",
       "      <td>MIDDLE RIVER</td>\n",
       "      <td>SA</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>5223</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>9/17/1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1042</td>\n",
       "      <td>Male</td>\n",
       "      <td>Aidan Pankhurst</td>\n",
       "      <td>TAWONGA SOUTH</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>3698</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>11/19/1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15261</th>\n",
       "      <td>2099600</td>\n",
       "      <td>Female</td>\n",
       "      <td>Denisa Duková</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>77017</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>3/25/1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15262</th>\n",
       "      <td>2099618</td>\n",
       "      <td>Male</td>\n",
       "      <td>Justin Solórzano</td>\n",
       "      <td>Mclean</td>\n",
       "      <td>VA</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>22101</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>2/16/1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15263</th>\n",
       "      <td>2099758</td>\n",
       "      <td>Male</td>\n",
       "      <td>Svend Petrussen</td>\n",
       "      <td>Wilmington</td>\n",
       "      <td>NC</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>28405</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>11/9/1937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15264</th>\n",
       "      <td>2099862</td>\n",
       "      <td>Female</td>\n",
       "      <td>Lorenza Rush</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>92501</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>10/12/1937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15265</th>\n",
       "      <td>2099937</td>\n",
       "      <td>Male</td>\n",
       "      <td>Zygmunt Kaminski</td>\n",
       "      <td>Bloomfield Township</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48302</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>8/18/1965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15266 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CustomerKey  Gender               Name                 City State Code  \\\n",
       "0              301  Female      Lilly Harding       WANDEARAH EAST         SA   \n",
       "1              325  Female       Madison Hull           MOUNT BUDD         WA   \n",
       "2              554  Female      Claire Ferres            WINJALLOK        VIC   \n",
       "3              786    Male  Jai Poltpalingada         MIDDLE RIVER         SA   \n",
       "4             1042    Male    Aidan Pankhurst        TAWONGA SOUTH        VIC   \n",
       "...            ...     ...                ...                  ...        ...   \n",
       "15261      2099600  Female     Denisa Duková              Houston         TX   \n",
       "15262      2099618    Male   Justin Solórzano               Mclean         VA   \n",
       "15263      2099758    Male    Svend Petrussen           Wilmington         NC   \n",
       "15264      2099862  Female       Lorenza Rush            Riverside         CA   \n",
       "15265      2099937    Male   Zygmunt Kaminski  Bloomfield Township         MI   \n",
       "\n",
       "                   State Zip Code        Country      Continent    Birthday  \n",
       "0        South Australia     5523      Australia      Australia    7/3/1939  \n",
       "1      Western Australia     6522      Australia      Australia   9/27/1979  \n",
       "2               Victoria     3380      Australia      Australia   5/26/1947  \n",
       "3        South Australia     5223      Australia      Australia   9/17/1957  \n",
       "4               Victoria     3698      Australia      Australia  11/19/1965  \n",
       "...                  ...      ...            ...            ...         ...  \n",
       "15261              Texas    77017  United States  North America   3/25/1936  \n",
       "15262           Virginia    22101  United States  North America   2/16/1992  \n",
       "15263     North Carolina    28405  United States  North America   11/9/1937  \n",
       "15264         California    92501  United States  North America  10/12/1937  \n",
       "15265           Michigan    48302  United States  North America   8/18/1965  \n",
       "\n",
       "[15266 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\3606214188.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customers['City'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\3606214188.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customers['State'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\3606214188.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customers['State Code'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\3606214188.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customers['Zip Code'].fillna(0, inplace=True)\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\3606214188.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customers['Country'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\3606214188.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customers['Continent'].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State_Code</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip_Code</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Birthday</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>Female</td>\n",
       "      <td>Lilly Harding</td>\n",
       "      <td>WANDEARAH EAST</td>\n",
       "      <td>SA</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>5523</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1939-07-03</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325</td>\n",
       "      <td>Female</td>\n",
       "      <td>Madison Hull</td>\n",
       "      <td>MOUNT BUDD</td>\n",
       "      <td>WA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>6522</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1979-09-27</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>554</td>\n",
       "      <td>Female</td>\n",
       "      <td>Claire Ferres</td>\n",
       "      <td>WINJALLOK</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>3380</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1947-05-26</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>786</td>\n",
       "      <td>Male</td>\n",
       "      <td>Jai Poltpalingada</td>\n",
       "      <td>MIDDLE RIVER</td>\n",
       "      <td>SA</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>5223</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1957-09-17</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1042</td>\n",
       "      <td>Male</td>\n",
       "      <td>Aidan Pankhurst</td>\n",
       "      <td>TAWONGA SOUTH</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>3698</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1965-11-19</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15261</th>\n",
       "      <td>2099600</td>\n",
       "      <td>Female</td>\n",
       "      <td>Denisa Duková</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>77017</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>1936-03-25</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15262</th>\n",
       "      <td>2099618</td>\n",
       "      <td>Male</td>\n",
       "      <td>Justin Solórzano</td>\n",
       "      <td>Mclean</td>\n",
       "      <td>VA</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>22101</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>1992-02-16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15263</th>\n",
       "      <td>2099758</td>\n",
       "      <td>Male</td>\n",
       "      <td>Svend Petrussen</td>\n",
       "      <td>Wilmington</td>\n",
       "      <td>NC</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>28405</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>1937-11-09</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15264</th>\n",
       "      <td>2099862</td>\n",
       "      <td>Female</td>\n",
       "      <td>Lorenza Rush</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>92501</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>1937-10-12</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15265</th>\n",
       "      <td>2099937</td>\n",
       "      <td>Male</td>\n",
       "      <td>Zygmunt Kaminski</td>\n",
       "      <td>Bloomfield Township</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48302</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>1965-08-18</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15266 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Customer_ID  Gender               Name                 City State_Code  \\\n",
       "0              301  Female      Lilly Harding       WANDEARAH EAST         SA   \n",
       "1              325  Female       Madison Hull           MOUNT BUDD         WA   \n",
       "2              554  Female      Claire Ferres            WINJALLOK        VIC   \n",
       "3              786    Male  Jai Poltpalingada         MIDDLE RIVER         SA   \n",
       "4             1042    Male    Aidan Pankhurst        TAWONGA SOUTH        VIC   \n",
       "...            ...     ...                ...                  ...        ...   \n",
       "15261      2099600  Female     Denisa Duková              Houston         TX   \n",
       "15262      2099618    Male   Justin Solórzano               Mclean         VA   \n",
       "15263      2099758    Male    Svend Petrussen           Wilmington         NC   \n",
       "15264      2099862  Female       Lorenza Rush            Riverside         CA   \n",
       "15265      2099937    Male   Zygmunt Kaminski  Bloomfield Township         MI   \n",
       "\n",
       "                   State Zip_Code        Country      Continent   Birthday  \\\n",
       "0        South Australia     5523      Australia      Australia 1939-07-03   \n",
       "1      Western Australia     6522      Australia      Australia 1979-09-27   \n",
       "2               Victoria     3380      Australia      Australia 1947-05-26   \n",
       "3        South Australia     5223      Australia      Australia 1957-09-17   \n",
       "4               Victoria     3698      Australia      Australia 1965-11-19   \n",
       "...                  ...      ...            ...            ...        ...   \n",
       "15261              Texas    77017  United States  North America 1936-03-25   \n",
       "15262           Virginia    22101  United States  North America 1992-02-16   \n",
       "15263     North Carolina    28405  United States  North America 1937-11-09   \n",
       "15264         California    92501  United States  North America 1937-10-12   \n",
       "15265           Michigan    48302  United States  North America 1965-08-18   \n",
       "\n",
       "       Age  \n",
       "0       85  \n",
       "1       44  \n",
       "2       77  \n",
       "3       66  \n",
       "4       58  \n",
       "...    ...  \n",
       "15261   88  \n",
       "15262   32  \n",
       "15263   86  \n",
       "15264   86  \n",
       "15265   59  \n",
       "\n",
       "[15266 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling Missing Values\n",
    "customers['City'].fillna('Unknown', inplace=True)\n",
    "customers['State'].fillna('Unknown', inplace=True)\n",
    "customers['State Code'].fillna('Unknown', inplace=True)  \n",
    "customers['Zip Code'].fillna(0, inplace=True)\n",
    "customers['Country'].fillna('Unknown', inplace=True)\n",
    "customers['Continent'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Correcting Data Types\n",
    "customers['Birthday'] = pd.to_datetime(customers['Birthday'], errors='coerce')\n",
    "\n",
    "# Removing Duplicates (excluding primary key and unique key)\n",
    "customers.drop_duplicates(subset=[col for col in customers.columns if col not in ['CustomerKey']], inplace=True)\n",
    "\n",
    "# Renaming Columns for Consistency\n",
    "customers.rename(columns={'CustomerKey': 'Customer_ID', 'Zip Code': 'Zip_Code', 'State Code': 'State_Code'}, inplace=True)\n",
    "\n",
    "# Handling Categorical Data\n",
    "customers['Gender'] = customers['Gender'].astype('category')\n",
    "\n",
    "# Calculate Age\n",
    "customers['Age'] = (pd.Timestamp.now() - customers['Birthday']).dt.total_seconds() / (60*60*24*365.25)\n",
    "customers['Age'] = customers['Age'].astype(int)\n",
    "\n",
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers data cleaning completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save cleaned dataset\n",
    "customers.to_csv('idealprocessed/customers.csv', index=False)\n",
    "\n",
    "print(\"Customers data cleaning completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\1967192741.py:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  sales = pd.read_csv('CSV files\\Sales.csv', encoding='ISO-8859-1')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "sales = pd.read_csv('CSV files\\Sales.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Number</th>\n",
       "      <th>Line Item</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Delivery Date</th>\n",
       "      <th>CustomerKey</th>\n",
       "      <th>StoreKey</th>\n",
       "      <th>ProductKey</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Currency Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>366000</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265598</td>\n",
       "      <td>10</td>\n",
       "      <td>1304</td>\n",
       "      <td>1</td>\n",
       "      <td>CAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366001</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>1/13/2016</td>\n",
       "      <td>1269051</td>\n",
       "      <td>0</td>\n",
       "      <td>1048</td>\n",
       "      <td>2</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>366001</td>\n",
       "      <td>2</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>1/13/2016</td>\n",
       "      <td>1269051</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>366002</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>1/12/2016</td>\n",
       "      <td>266019</td>\n",
       "      <td>0</td>\n",
       "      <td>1106</td>\n",
       "      <td>7</td>\n",
       "      <td>CAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>366002</td>\n",
       "      <td>2</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>1/12/2016</td>\n",
       "      <td>266019</td>\n",
       "      <td>0</td>\n",
       "      <td>373</td>\n",
       "      <td>1</td>\n",
       "      <td>CAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62879</th>\n",
       "      <td>2243030</td>\n",
       "      <td>1</td>\n",
       "      <td>2/20/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1216913</td>\n",
       "      <td>43</td>\n",
       "      <td>632</td>\n",
       "      <td>3</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62880</th>\n",
       "      <td>2243031</td>\n",
       "      <td>1</td>\n",
       "      <td>2/20/2021</td>\n",
       "      <td>2/24/2021</td>\n",
       "      <td>511229</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62881</th>\n",
       "      <td>2243032</td>\n",
       "      <td>1</td>\n",
       "      <td>2/20/2021</td>\n",
       "      <td>2/23/2021</td>\n",
       "      <td>331277</td>\n",
       "      <td>0</td>\n",
       "      <td>1613</td>\n",
       "      <td>2</td>\n",
       "      <td>CAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62882</th>\n",
       "      <td>2243032</td>\n",
       "      <td>2</td>\n",
       "      <td>2/20/2021</td>\n",
       "      <td>2/23/2021</td>\n",
       "      <td>331277</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>2</td>\n",
       "      <td>CAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62883</th>\n",
       "      <td>2243032</td>\n",
       "      <td>3</td>\n",
       "      <td>2/20/2021</td>\n",
       "      <td>2/23/2021</td>\n",
       "      <td>331277</td>\n",
       "      <td>0</td>\n",
       "      <td>464</td>\n",
       "      <td>7</td>\n",
       "      <td>CAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62884 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Order Number  Line Item Order Date Delivery Date  CustomerKey  \\\n",
       "0            366000          1   1/1/2016           NaN       265598   \n",
       "1            366001          1   1/1/2016     1/13/2016      1269051   \n",
       "2            366001          2   1/1/2016     1/13/2016      1269051   \n",
       "3            366002          1   1/1/2016     1/12/2016       266019   \n",
       "4            366002          2   1/1/2016     1/12/2016       266019   \n",
       "...             ...        ...        ...           ...          ...   \n",
       "62879       2243030          1  2/20/2021           NaN      1216913   \n",
       "62880       2243031          1  2/20/2021     2/24/2021       511229   \n",
       "62881       2243032          1  2/20/2021     2/23/2021       331277   \n",
       "62882       2243032          2  2/20/2021     2/23/2021       331277   \n",
       "62883       2243032          3  2/20/2021     2/23/2021       331277   \n",
       "\n",
       "       StoreKey  ProductKey  Quantity Currency Code  \n",
       "0            10        1304         1           CAD  \n",
       "1             0        1048         2           USD  \n",
       "2             0        2007         1           USD  \n",
       "3             0        1106         7           CAD  \n",
       "4             0         373         1           CAD  \n",
       "...         ...         ...       ...           ...  \n",
       "62879        43         632         3           USD  \n",
       "62880         0          98         4           EUR  \n",
       "62881         0        1613         2           CAD  \n",
       "62882         0        1717         2           CAD  \n",
       "62883         0         464         7           CAD  \n",
       "\n",
       "[62884 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales data cleaning completed.\n"
     ]
    }
   ],
   "source": [
    "# Define primary and unique key columns\n",
    "primary_keys_sales = ['Order Number', 'Line Item', 'CustomerKey', 'StoreKey', 'ProductKey']\n",
    "\n",
    "# Handling Missing Values\n",
    "sales.dropna(subset=['Order Date'], inplace=True)\n",
    "\n",
    "# Correcting Data Types\n",
    "sales['Order Date'] = pd.to_datetime(sales['Order Date'], errors='coerce')\n",
    "\n",
    "# Handling Outliers (e.g., capping extreme values in Quantity)\n",
    "sales['Quantity'] = np.where(sales['Quantity'] > sales['Quantity'].quantile(0.99), sales['Quantity'].quantile(0.99), sales['Quantity'])\n",
    "\n",
    "# Removing Duplicates\n",
    "sales.drop_duplicates(inplace=True)\n",
    "\n",
    "# High Percentage of Missing Values\n",
    "threshold = 0.5\n",
    "columns_to_drop = [col for col in sales.columns if sales[col].isnull().sum() / len(sales) > threshold and col not in primary_keys_sales]\n",
    "\n",
    "# Drop irrelevant, low variance, redundant, high correlation, and privacy-sensitive columns as per conditions\n",
    "sales.drop(columns=set(columns_to_drop), inplace=True)\n",
    "\n",
    "# Save cleaned dataset\n",
    "sales.to_csv('idealprocessed/sales.csv', index=False)\n",
    "\n",
    "print(\"Sales data cleaning completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StoreKey    Country                         State  Square Meters  Open Date\n",
      "0         1  Australia  Australian Capital Territory          595.0   1/1/2008\n",
      "1         2  Australia            Northern Territory          665.0  1/12/2008\n",
      "2         3  Australia               South Australia         2000.0   1/7/2012\n",
      "3         4  Australia                      Tasmania         2000.0   1/1/2010\n",
      "4         5  Australia                      Victoria         2000.0  12/9/2015\n",
      "Stores data cleaning completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\1569395229.py:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  stores = pd.read_csv('CSV files\\Stores.csv', encoding='ISO-8859-1')\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\1569395229.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  stores['Country'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\1569395229.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  stores['State'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\1569395229.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  stores['Square Meters'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoreKey</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Square Meters</th>\n",
       "      <th>Open Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australian Capital Territory</td>\n",
       "      <td>595.0</td>\n",
       "      <td>2008-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Northern Territory</td>\n",
       "      <td>665.0</td>\n",
       "      <td>2008-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Australia</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2012-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Tasmania</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2010-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2015-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>United States</td>\n",
       "      <td>Utah</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2008-03-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>United States</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>2010-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>United States</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>2012-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>United States</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>Online</td>\n",
       "      <td>Online</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    StoreKey        Country                         State  Square Meters  \\\n",
       "0          1      Australia  Australian Capital Territory          595.0   \n",
       "1          2      Australia            Northern Territory          665.0   \n",
       "2          3      Australia               South Australia         2000.0   \n",
       "3          4      Australia                      Tasmania         2000.0   \n",
       "4          5      Australia                      Victoria         2000.0   \n",
       "..       ...            ...                           ...            ...   \n",
       "62        63  United States                          Utah         2000.0   \n",
       "63        64  United States                 Washington DC         1330.0   \n",
       "64        65  United States                 West Virginia         1785.0   \n",
       "65        66  United States                       Wyoming          840.0   \n",
       "66         0         Online                        Online            0.0   \n",
       "\n",
       "    Open Date  \n",
       "0  2008-01-01  \n",
       "1  2008-01-12  \n",
       "2  2012-01-07  \n",
       "3  2010-01-01  \n",
       "4  2015-12-09  \n",
       "..        ...  \n",
       "62 2008-03-06  \n",
       "63 2010-01-01  \n",
       "64 2012-01-01  \n",
       "65 2014-01-01  \n",
       "66 2010-01-01  \n",
       "\n",
       "[67 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "stores = pd.read_csv('CSV files\\Stores.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Display the first few rows to understand the data\n",
    "print(stores.head())\n",
    "\n",
    "# Handling Missing Values\n",
    "\n",
    "stores['Country'].fillna('Unknown', inplace=True)\n",
    "stores['State'].fillna('Unknown', inplace=True)\n",
    "stores['Square Meters'].fillna(0, inplace=True)\n",
    "\n",
    "# Correcting Data Types\n",
    "stores['Open Date'] = pd.to_datetime(stores['Open Date'], errors='coerce')\n",
    "\n",
    "# Removing Duplicates (excluding primary key)\n",
    "stores.drop_duplicates(subset=[col for col in stores.columns if col not in ['StoreKey']], inplace=True)\n",
    "\n",
    "# Handle Inconsistent Data (if any)\n",
    "\n",
    "# Save cleaned dataset\n",
    "stores.to_csv('idealprocessed/stores.csv', index=False)\n",
    "\n",
    "print(\"Stores data cleaning completed.\")\n",
    "stores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Unit Cost USD to numeric successfully.\n",
      "Converted Unit Price USD to numeric successfully.\n",
      "Products data cleaning completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\2700221647.py:4: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  products = pd.read_csv('CSV files\\Products.csv', encoding='ISO-8859-1')\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\2700221647.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  products['Color'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "products = pd.read_csv('CSV files\\Products.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Handling Missing Values\n",
    "products['Color'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Removing Duplicates\n",
    "products.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove currency symbols before converting to numeric\n",
    "for column in ['Unit Cost USD', 'Unit Price USD']:\n",
    "    products[column] = products[column].str.replace('$', '').str.replace(',', '')\n",
    "\n",
    "# Correcting Data Types (e.g., converting cost and price to numeric)\n",
    "for column in ['Unit Cost USD', 'Unit Price USD']:\n",
    "    try:\n",
    "        products[column] = pd.to_numeric(products[column], errors='coerce')\n",
    "        print(f\"Converted {column} to numeric successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {column} to numeric: {e}\")\n",
    "\n",
    "# Additional step to handle missing values in cost and price columns\n",
    "for column in ['Unit Cost USD', 'Unit Price USD']:\n",
    "    if products[column].isnull().any():\n",
    "        products[column].fillna(products[column].median(), inplace=True)\n",
    "        print(f\"Filled missing values in {column} with the median.\")\n",
    "\n",
    "# Save cleaned dataset\n",
    "products.to_csv('idealprocessed/products.csv', index=False)\n",
    "\n",
    "print(\"Products data cleaning completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exchange rates data cleaning completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\E'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\E'\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\2863279714.py:4: SyntaxWarning: invalid escape sequence '\\E'\n",
      "  exchange_rates = pd.read_csv('CSV files\\Exchange_Rates.csv', encoding='ISO-8859-1')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "exchange_rates = pd.read_csv('CSV files\\Exchange_Rates.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Correcting Data Types\n",
    "exchange_rates['Date'] = pd.to_datetime(exchange_rates['Date'], errors='coerce')\n",
    "\n",
    "# Removing Duplicates\n",
    "exchange_rates.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save cleaned dataset\n",
    "exchange_rates.to_csv('idealprocessed/exchangerates.csv', index=False)\n",
    "\n",
    "print(\"Exchange rates data cleaning completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\e'\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\3266425439.py:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  customers = pd.read_csv('idealprocessed\\customers.csv', encoding='ISO-8859-1')\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\3266425439.py:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  sales = pd.read_csv('idealprocessed\\sales.csv', encoding='ISO-8859-1')\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\3266425439.py:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  stores = pd.read_csv('idealprocessed\\stores.csv', encoding='ISO-8859-1')\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\3266425439.py:7: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  products = pd.read_csv('idealprocessed\\products.csv', encoding='ISO-8859-1')\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\3266425439.py:8: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  exchange_rates = pd.read_csv('idealprocessed\\exchangerates.csv', encoding='ISO-8859-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data merging completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned datasets\n",
    "customers = pd.read_csv('idealprocessed\\customers.csv', encoding='ISO-8859-1')\n",
    "sales = pd.read_csv('idealprocessed\\sales.csv', encoding='ISO-8859-1')\n",
    "stores = pd.read_csv('idealprocessed\\stores.csv', encoding='ISO-8859-1')\n",
    "products = pd.read_csv('idealprocessed\\products.csv', encoding='ISO-8859-1')\n",
    "exchange_rates = pd.read_csv('idealprocessed\\exchangerates.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Merge sales with customers\n",
    "sales_customers = pd.merge(sales, customers, how='left', left_on='CustomerKey', right_on='Customer_ID')\n",
    "\n",
    "# Merge sales_customers with stores\n",
    "sales_customers_stores = pd.merge(sales_customers, stores, how='left', left_on='StoreKey', right_on='StoreKey')\n",
    "\n",
    "# Merge sales_customers_stores with products\n",
    "sales_customers_stores_products = pd.merge(sales_customers_stores, products, how='left', left_on='ProductKey', right_on='ProductKey')\n",
    "\n",
    "# Optionally, merge with exchange rates if needed (e.g., if there are columns that need exchange rates)\n",
    "# Assuming you might want to join on a common date column, which isn't directly mentioned in the given datasets\n",
    "# sales_customers_stores_products = pd.merge(sales_customers_stores_products, exchange_rates, how='left', left_on='Date', right_on='Date')\n",
    "\n",
    "# Save the merged dataset\n",
    "sales_customers_stores_products.to_csv('idealprocessed/merged.csv', index=False)\n",
    "\n",
    "print(\"Data merging completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\welcome\\desktop\\data_spark_guvi\\.venv\\lib\\site-packages (2.2.2)\n",
      "Collecting sqlalchemy\n",
      "  Downloading SQLAlchemy-2.0.34-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting mysql-connector-python\n",
      "  Downloading mysql_connector_python-9.0.0-cp312-cp312-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\welcome\\desktop\\data_spark_guvi\\.venv\\lib\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\welcome\\desktop\\data_spark_guvi\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\welcome\\desktop\\data_spark_guvi\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\welcome\\desktop\\data_spark_guvi\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Collecting typing-extensions>=4.6.0 (from sqlalchemy)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy)\n",
      "  Downloading greenlet-3.0.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\welcome\\desktop\\data_spark_guvi\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading SQLAlchemy-2.0.34-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 28.9 MB/s eta 0:00:00\n",
      "Downloading mysql_connector_python-9.0.0-cp312-cp312-win_amd64.whl (14.3 MB)\n",
      "   ---------------------------------------- 0.0/14.3 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 5.5/14.3 MB 30.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.7/14.3 MB 24.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.3/14.3 MB 24.4 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.3-cp312-cp312-win_amd64.whl (293 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, mysql-connector-python, greenlet, sqlalchemy\n",
      "Successfully installed greenlet-3.0.3 mysql-connector-python-9.0.0 sqlalchemy-2.0.34 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas sqlalchemy mysql-connector-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\WELCOME\\AppData\\Local\\Temp\\ipykernel_3244\\2444957660.py:5: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  file_path = 'idealprocessed\\merged.csv'  # Path to your uploaded file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62884"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "file_path = 'idealprocessed\\merged.csv'  # Path to your uploaded file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "user = 'root'\n",
    "password = 'root'\n",
    "host = 'localhost'  # Replace with your MySQL host if not localhost\n",
    "database = 'dataspark'\n",
    "\n",
    "# Create connection string\n",
    "connection_string = f'mysql+mysqlconnector://{user}:{password}@{host}/{database}'\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "table_name = 'mergeddata'\n",
    "df.to_sql(table_name, con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets successfully stored in the SQLite database.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to the cleaned datasets\n",
    "customers_path = 'D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_customers.csv'\n",
    "sales_path = 'D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_sales.csv'\n",
    "stores_path = 'D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_stores.csv'\n",
    "products_path = 'D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_products.csv'\n",
    "exchange_rates_path = 'D:\\\\Guvi\\\\projects\\\\Data Spark\\\\cleaned_exchange_rates.csv'\n",
    "merged_data_path = 'D:\\\\Guvi\\\\projects\\\\Data Spark\\\\merged_data.csv'\n",
    "\n",
    "# Path to the SQLite database\n",
    "db_path = 'D:\\\\Guvi\\\\projects\\\\Data Spark\\\\Data_Spark.db'\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Load each dataset\n",
    "customers = pd.read_csv(customers_path)\n",
    "sales = pd.read_csv(sales_path)\n",
    "stores = pd.read_csv(stores_path)\n",
    "products = pd.read_csv(products_path)\n",
    "exchange_rates = pd.read_csv(exchange_rates_path)\n",
    "merged_data = pd.read_csv(merged_data_path)\n",
    "\n",
    "# Insert each DataFrame into the SQLite database\n",
    "customers.to_sql('Customers', conn, if_exists='replace', index=False)\n",
    "sales.to_sql('Sales', conn, if_exists='replace', index=False)\n",
    "stores.to_sql('Stores', conn, if_exists='replace', index=False)\n",
    "products.to_sql('Products', conn, if_exists='replace', index=False)\n",
    "exchange_rates.to_sql('ExchangeRates', conn, if_exists='replace', index=False)\n",
    "merged_data.to_sql('MergedData', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "print(\"All datasets successfully stored in the SQLite database.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
